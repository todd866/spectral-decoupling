\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{gomez2008entropy,braunstein2006laplacian}
\citation{grassberger1983measuring}
\citation{takens1981detecting,sauer1991embedology}
\citation{kaplan1979chaotic}
\citation{eckmann1985ergodic}
\citation{eckmann1985ergodic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretical Framework}{2}{section.2}\protected@file@percent }
\newlabel{sec:theory}{{2}{2}{Theoretical Framework}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Network Diffusion Dynamics}{2}{subsection.2.1}\protected@file@percent }
\newlabel{eq:diffusion}{{2}{2}{Network Diffusion Dynamics}{equation.2}{}}
\citation{lempel1976complexity}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Spectral Effective Dimension}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Entropy Rate}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Spectral Decoupling Theorem}{3}{section.3}\protected@file@percent }
\newlabel{sec:theorem}{{3}{3}{Spectral Decoupling Theorem}{section.3}{}}
\newlabel{thm:decoupling}{{2}{3}{Spectral Decoupling}{theorem.2}{}}
\citation{watts1998collective}
\citation{barabasi1999emergence}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{4}{section.4}\protected@file@percent }
\newlabel{sec:results}{{4}{4}{Results}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Phase Portrait Across Topologies}{4}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces $(D, h_\mu )$ phase portrait across network topologies. Each curve shows how a network moves through dimension-entropy space as noise varies. Different architectures trace distinct trajectories, demonstrating that $D$ and $h_\mu $ are independently controlled.}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:phase_portrait}{{1}{5}{$(D, \hmu )$ phase portrait across network topologies. Each curve shows how a network moves through dimension-entropy space as noise varies. Different architectures trace distinct trajectories, demonstrating that $D$ and $\hmu $ are independently controlled}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Iso-Entropy Comparison}{5}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Iso-Dimension Demonstration}{5}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Spectral Mechanism}{5}{subsection.4.4}\protected@file@percent }
\citation{stringer2019high,cunningham2014dimensionality}
\citation{schartner2017increased}
\citation{bertschinger2004real,beggs2003neuronal}
\citation{eckmann1985ergodic,grassberger1983measuring}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Iso-entropy, different dimension. Left: $D_{\mathrm  {eff}}$ differs substantially across topologies. Right: entropy is matched by tuning noise. This confirms that entropy does not determine geometric dimensionality.}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:isoentropic}{{2}{6}{Iso-entropy, different dimension. Left: $\Deff $ differs substantially across topologies. Right: entropy is matched by tuning noise. This confirms that entropy does not determine geometric dimensionality}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{6}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Implications for Network Complexity}{6}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Relation to Prior Work}{6}{subsection.5.2}\protected@file@percent }
\citation{gomez2008entropy}
\citation{lacasa2013correlation}
\citation{faccin2018entrograms}
\bibstyle{abbrvnat}
\bibdata{references}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Iso-dimension, different entropy. For a fixed modular network, $D_{\mathrm  {eff}}$ is stable across noise levels while $h_\mu $ varies continuously. This confirms that dimensionality does not determine entropy.}}{7}{figure.3}\protected@file@percent }
\newlabel{fig:isodimensional}{{3}{7}{Iso-dimension, different entropy. For a fixed modular network, $\Deff $ is stable across noise levels while $\hmu $ varies continuously. This confirms that dimensionality does not determine entropy}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Limitations and Extensions}{7}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{7}{section.6}\protected@file@percent }
\bibcite{barabasi1999emergence}{{1}{1999}{{Barab{\'a}si and Albert}}{{}}}
\bibcite{beggs2003neuronal}{{2}{2003}{{Beggs and Plenz}}{{}}}
\bibcite{bertschinger2004real}{{3}{2004}{{Bertschinger and Natschl{\"a}ger}}{{}}}
\bibcite{braunstein2006laplacian}{{4}{2006}{{Braunstein et~al.}}{{Braunstein, Ghosh, and Severini}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Laplacian spectra and spectral dimension. The dashed line marks the threshold $\lambda ^* = 1/(\alpha \tau )$; modes below this threshold contribute to $D_{\mathrm  {eff}}(\tau )$. Modular and ring networks have many slow modes; random and scale-free networks have fewer.}}{8}{figure.4}\protected@file@percent }
\newlabel{fig:spectral}{{4}{8}{Laplacian spectra and spectral dimension. The dashed line marks the threshold $\lambda ^* = 1/(\alpha \tau )$; modes below this threshold contribute to $\Deff (\tau )$. Modular and ring networks have many slow modes; random and scale-free networks have fewer}{figure.4}{}}
\bibcite{cunningham2014dimensionality}{{5}{2014}{{Cunningham and Yu}}{{}}}
\bibcite{eckmann1985ergodic}{{6}{1985}{{Eckmann and Ruelle}}{{}}}
\bibcite{faccin2018entrograms}{{7}{2018}{{Faccin et~al.}}{{Faccin, Schaub, and Delvenne}}}
\bibcite{gomez2008entropy}{{8}{2008}{{G{\'o}mez-Garde{\~n}es and Latora}}{{}}}
\bibcite{grassberger1983measuring}{{9}{1983}{{Grassberger and Procaccia}}{{}}}
\bibcite{kaplan1979chaotic}{{10}{1979}{{Kaplan and Yorke}}{{}}}
\bibcite{lacasa2013correlation}{{11}{2013}{{Lacasa and G{\'o}mez-Garde{\~n}es}}{{}}}
\bibcite{lempel1976complexity}{{12}{1976}{{Lempel and Ziv}}{{}}}
\bibcite{sauer1991embedology}{{13}{1991}{{Sauer et~al.}}{{Sauer, Yorke, and Casdagli}}}
\bibcite{schartner2017increased}{{14}{2017}{{Schartner et~al.}}{{Schartner, Carhart-Harris, Barrett, Seth, and Muthukumaraswamy}}}
\bibcite{stringer2019high}{{15}{2019}{{Stringer et~al.}}{{Stringer, Pachitariu, Steinmetz, Carandini, and Harris}}}
\bibcite{takens1981detecting}{{16}{1981}{{Takens}}{{}}}
\bibcite{watts1998collective}{{17}{1998}{{Watts and Strogatz}}{{}}}
\gdef \@abspage@last{9}
